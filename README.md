# NutriVoice: "See with AI, Eat with Confidence"

##  Inspiration

The inspiration for NutriVoice came from a simple yet critical question:  
**How can blind individuals easily access nutritional information about their food?**  

Many existing nutrition apps rely heavily on visual elements, making them inaccessible to the visually impaired. We wanted to **bridge this gap** using AI-powered speech and vision technologies, ensuring that **everyone, regardless of ability, can make informed dietary choices.**  

##  What It Does

NutriVoice is an AI-powered nutrition assistant designed to help **blind and visually impaired users** track their daily calorie intake through voice commands and food recognition.  

The app allows users to:  
- **Set personal dietary goals** based on weight, height and timeframe.  
- **Scan food items** using their phone's camera.  
- **Receive instant calorie estimations** via AI-powered food recognition.  
- **Use voice commands** for seamless interaction.  
- **Track daily calorie intake** to stay on course with their nutrition goals.  

##  How We Built It

We leveraged cutting-edge AI technologies to develop NutriVoice:  

- **OpenAI’s Vision API** for food recognition and calorie estimation.  
- **Groq’s Whisper API** for real-time speech-to-text processing.  
- **A custom nutrition database** to cross-reference food data and provide accurate calorie values.  
- **A voice-first interface** to ensure accessibility for visually impaired users.  
- **Python & Flask backend** to process user data and integrate AI models.  

##  Challenges We Ran Into

Building NutriVoice was not without its hurdles:  

- **AI Accuracy** – Ensuring precise food recognition and calorie estimations required extensive testing and prompt engineering refinement.  
- **Speech Processing Latency** – Optimizing Whisper API’s response time to provide **real-time feedback** was challenging.  
- **Data Constraints** – Some food items lacked well-documented calorie data, requiring integration with multiple nutrition databases.  
- **User Accessibility Testing** – Designing a voice-first experience for the visually impaired required iterative testing and feedback.  

##  Accomplishments That We're Proud Of

- **Developing a fully functional AI-powered nutrition assistant.**  
- **Achieving high accuracy** in food recognition and calorie estimation.  
- **Creating an intuitive voice-first experience** that makes nutrition tracking accessible to visually impaired users.  
- **Successfully integrating speech recognition** for seamless hands-free operation.  

##  What We Learned

Throughout the development of NutriVoice, we gained valuable insights:  

- **Accessibility must be at the core of design** – Ensuring that all features are optimized for voice-based interactions was key.  
- **AI models require constant improvement** – Fine-tuning food recognition and calorie estimation models was a major learning curve.  
- **User experience matters** – We had to refine speech-to-text interactions to minimize errors and enhance usability.  

##  What's Next for NutriVoice

NutriVoice is just the beginning! Future plans include:  

- **Personalized meal recommendations** based on dietary preferences.  
- **Multi-language support** to make the app accessible worldwide.  
- **Crowdsourced food database expansion** to improve accuracy and include more local cuisines.  
- **Offline functionality** to allow users to track nutrition without an internet connection.  

With NutriVoice, we aim to **redefine nutrition accessibility** and empower individuals to take control of their health through AI-driven innovation. 
